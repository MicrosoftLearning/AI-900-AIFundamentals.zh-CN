{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 文本分析\r\n",
        "\r\n",
        "自然语言处理 (NLP) 是人工智能 (AI) 的一个分支，用于处理手写以及口头语言。可以使用 NLP 构建从文本或语音中提取语义含义或者使用自然语言发出合理回应的解决方案。\r\n",
        "\r\n",
        "Microsoft Azure *认知服务*包括*文本分析*服务，该服务提供了一些现成的 NLP 功能，包括识别文本中的关键短语和基于情绪对文本分类。\r\n",
        "\r\n",
        "![正在阅读笔记的机器人](./images/NLP.jpg)\r\n",
        "\r\n",
        "例如，假设虚构的 *Margie's Travel* 组织鼓励客户提交关于酒店住宿的评价。使用文本分析服务，可以通过提取关键短语来对评价进行总结，确定哪些评价是正面的，哪些是负面的，或者分析评价文本中提到的已知实体（如地点或人员）。\r\n",
        "\r\n",
        "## 查看评价文档\r\n",
        "\r\n",
        "让我们先来看看顾客留下的一些酒店评价。\r\n",
        "\r\n",
        "这些评价都包含在文本文件中。要查看它们，只需单击位于单元格左侧的“**运行单元格**”(&#9655;) 按钮以运行下方的代码即可。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 创建认知服务资源\r\n",
        "\r\n",
        "要分析这些评价中的文本，可以使用**文本分析**认知服务。要使用该服务，你需要在 Azure 订阅中预配**文本分析**或**认知服务**资源（如果仅计划使用这一项服务或者想单独跟踪它的使用情况，则使用文本分析资源；否则，可以使用认知服务资源将文本分析服务与其他认知服务结合使用，使开发人员能够使用单个终结点和密钥来访问它们。）\r\n",
        "\r\n",
        "请按照以下步骤在 Azure 订阅中创建**认知服务**资源（如果还没有该资源）：\r\n",
        "\r\n",
        "> **备注**：如果已有认知服务资源，则只需在 Azure 门户中打开其“**快速入门**”页面，然后将其密钥和终结点复制到下面的单元格中即可。否则，请按照以下步骤创建认知服务资源。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 (https://portal.azure.com) 并使用 Microsoft 帐户登录。\r\n",
        "2. 单击“**&#65291;创建资源**”按钮，搜索“*认知服务*”并以如下设置创建**认知服务**资源：\r\n",
        "    - **订阅**： *你的 Azure 订阅*。\r\n",
        "    - **资源组**： *选择或创建具有唯一名称的资源组*。\r\n",
        "    - **区域**： *选择任何可用区域*：\r\n",
        "    - **名称**： *输入一个唯一名称*。\r\n",
        "    - **定价层**：中的机器人 S0\r\n",
        "    - **我确认我已阅读并理解上述通知**：已选中。\r\n",
        "3. 等待部署完成。然后转到认知服务资源，并单击“**概述**”页面上的链接以管理该服务的密钥。你将需要使用终结点和密钥从客户端应用程序连接到认知服务资源。\r\n",
        "\r\n",
        "### 获取认知服务资源的密钥和终结点\r\n",
        "\r\n",
        "要使用认知服务资源，客户端应用程序需要其终结点和身份验证密钥：\r\n",
        "\r\n",
        "1. 进入 Azure 门户，在认知服务资源的“**密钥和终结点**”页面上复制资源的“**Key1**”，并将其粘贴到以下代码中，替换“**YOUR_COG_KEY**”。\r\n",
        "2. 复制资源的**终结点**，并将其粘贴到以下代码中，替换“**YOUR_COG_ENDPOINT**”。\r\n",
        "3. 通过单击绿色的 <span style=\"color:green\">&#9655;</span> 按钮运行下方单元格中的代码。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 检测语言\r\n",
        "让我们先确定这些评价所采用的语言。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 提取关键短语\r\n",
        "\r\n",
        "现在可以分析客户评价中的文本，识别一些能体现客户主要观点的关键短语。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "关键短语可以帮助你了解每条评价中最重要的观点。例如，如果评价中包含“工作人员乐于助人”或“服务差劲”这样的短语，你就可了解到一些评价者最在意的问题。\r\n",
        "\r\n",
        "## 判断情绪\r\n",
        "\r\n",
        "此功能可用于根据*情绪评分*将评价分为*正面*评价或*负面*评价。同样，你可以使用文本分析服务来做到这一点。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5,\n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 提取已知实体\r\n",
        "\r\n",
        "*实体*是指可能在文本中提到的内容，涉及一些人们所熟知的项目类型。例如地点、人员或日期。假设你想了解评价中提到的日期和地点，则可使用下面的代码来查找这些信息。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "请注意，有些知名实体会具有与之关联的 Wikipedia 页面，在这种情况下，文本分析服务会返回该页面的 URL。\r\n",
        "\r\n",
        "## 了解详细信息\r\n",
        "\r\n",
        "有关文本分析服务的详细信息，请参阅[文本分析服务文档](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}