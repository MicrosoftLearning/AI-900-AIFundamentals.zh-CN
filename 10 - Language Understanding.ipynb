{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 语言理解\r\n",
        "\r\n",
        "我们越来越希望计算机能够使用 AI 来理解用自然语言口述或键入的命令。例如，你或许想实现一种家庭自动化系统，使你能够使用语音命令（例如“开灯”或“打开风扇”）控制家中的设备，以及让 AI 提供支持的设备理解命令并采取适当行动。\r\n",
        "\r\n",
        "![在倾听的机器人](./images/language_understanding.jpg)\r\n",
        "\r\n",
        "## 创建创作资源和预测资源\r\n",
        "\r\n",
        "Microsoft 认知服务包括语言理解服务，该服务使你能够根据*言语*定义应用于*实体*的*意向*。 \r\n",
        "\r\n",
        "若要使用语言理解服务，你需要两种资源：\r\n",
        "\r\n",
        "- *创作*资源：用于定义训练和测试语言模型。这必须是 Azure 订阅**中的语言理解 - 创作**资源。\r\n",
        "- *预测*资源：用于发布模型并处理来自使用该模型的客户端应用程序的请求。这可以是 Azure 订阅**中的语言理解**或**认知服务**资源。\r\n",
        "\r\n",
        "可以使用**语言理解**或**认知服务**资源来*发布*语言理解应用，但必须创建一种单独的**语言理解**资源来*创作*该应用。\r\n",
        "\r\n",
        "> **重要信息**：创作资源必须在三个*区域*（欧洲、澳大利亚或美国）其中之一创建。在欧洲或澳大利亚的创作资源中创建的模型只能分别部署到欧洲或澳大利亚的预测资源。在美国创作资源中创建的模型可部署到除欧洲和澳大利亚之外的任何 Azure 位置的预测资源。有关匹配的创作位置和预测位置的详细信息，请参阅[创作和发布区域文档](https://docs.microsoft.com/azure/cognitive-services/luis/luis-reference-regions)。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 ([https://portal.azure.com](https://portal.azure.com)) 并使用 Microsoft 帐户登录。\r\n",
        "2. 单击“**+ 创建资源**”，并搜索“*语言理解*”。\r\n",
        "3. 在服务列表中，单击“**语言理解**”。\r\n",
        "4. 在“**语言理解**”边栏选项卡中，单击“**创建**”。\r\n",
        "5. 在“**创建**”边栏选项卡中，输入以下详细信息，然后单击“**创建**”\r\n",
        "   - **创建选项**：均可\r\n",
        "   - **名称**： *服务的唯一名称*\r\n",
        "   - **订阅**： *选择 Azure 订阅*\r\n",
        "   - **资源组**： *选择现有资源组或新建一个*\r\n",
        "   - **创作位置**： *选择你的首选位置*\r\n",
        "   - **创作定价层**：中的机器人 F0\r\n",
        "   - **预测位置**： *在与创作位置相同的区域中选择一个位置*\r\n",
        "   - **预测定价层**：中的机器人 F0\r\n",
        "   \r\n",
        "6. 等待资源创建完毕，并观察预配的两种语言理解资源；一个用于创作，另一个用于预测。导航到创建这些资源时所在的资源组，即可查看资源。\r\n",
        "\r\n",
        "### 创建语言理解应用\r\n",
        "\r\n",
        "若要使用语言理解来实现自然语言理解，你可以创建一款应用；然后添加实体、意向和言语来定义你希望应用理解的命令：\r\n",
        "\r\n",
        "1. 在新的浏览器选项卡中，为你用于创建创作资源的创作区域打开语言理解门户：\r\n",
        "    - 美国：[https://www.luis.ai](https://www.luis.ai)\r\n",
        "    - 欧洲：[https://eu.luis.ai](https://eu.luis.ai)\r\n",
        "    - 澳大利亚：[https://au.luis.ai](https://au.luis.ai)\r\n",
        "\r\n",
        "2. 使用与 Azure 订阅关联的 Microsoft 帐户登录。如果这是你首次登录语言理解门户，可能需要授予该应用一些权限，用于访问你的帐户详细信息。然后，通过选择刚刚在 Azure 订阅中创建的现有语言理解创作资源来完成“*欢迎*”步骤。 \r\n",
        "\r\n",
        "3. 打开“**对话应用**”页面，选择你的订阅和语言理解创作资源。然后使用以下设置创建一个新的对话应用：\r\n",
        "   - **名称**：Home Automation\r\n",
        "   - **区域性**：中文(中国) （*如果此选项不可用，请将其留空*）\r\n",
        "   - **说明**：简单的家庭自动化\r\n",
        "   - **预测资源**： *语言理解预测资源*\r\n",
        "\r\n",
        "4. 如果显示了含有有关创建有效语言理解应用的提示的面板，请关闭该面板。\r\n",
        "\r\n",
        "### 创建实体\r\n",
        "\r\n",
        "*实体*是语言模型可以识别并对其执行某些操作的事物。在这种情况下，语言理解应用将用于控制办公室中的各种*设备*，如灯具或风扇；因此，你将创建一个*设备*实体，其中包含你希望应用要配合使用的设备的类型列表。对于每种设备类型，你将创建一个子列表，该子列表标识设备的名称（例如“*light*”）以及可能用于指代该类型设备的任何同义词（例如“*lamp*”）。\r\n",
        "\r\n",
        "1. 在应用的“语言理解”页的左侧窗格中，单击“**实体**”。然后单击“**创建**”，并创建一个名为 **device** 的新实体，选择“**列表**”类型，然后单击“**创建**”。\r\n",
        "2. 在“**列表项**”页的“**规范化值**”下，键入“**light**”，然后按 Enter。\r\n",
        "3. 添加 **light** 值后，在“**同义词**”下，键入“**lamp**”并按 Enter。\r\n",
        "4. 添加另一个名为 **fan** 的列表项，其同义词为 **AC**。\r\n",
        "\r\n",
        "> **备注**：就本实验室而言，请按照说明使用准确的小写或大写文本_（例如：light 而**不是** Light）_，并且不要添加多余的空格。 \r\n",
        "\r\n",
        "### 创建意向\r\n",
        "\r\n",
        "*意向*是要在一个或多个实体上执行的操作。例如，你可能需要打开灯或关闭风扇。在这种情况下，你将定义两种意向：一个用于打开设备，另一个用于关闭设备。对于每种意向，你将指定示例*言语*，这些言语可指示用于表明意向的语言种类。\r\n",
        "\r\n",
        "> **备注**：就本实验室而言，请按照说明使用准确的小写或大写文本_（例如：“turn the light on”而**不是**“Turn the light on”。）_，并且不要添加多余的空格。 \r\n",
        "\r\n",
        "1. 在左侧导航窗格中，单击“**意向**”。然后单击“**创建**”，并添加名称为 **switch_on** 的意向，然后单击“**完成**”。\r\n",
        "2. 在“**示例**”标题和“**示例用户输入**”副标题下，键入言语“***turn the light on***”，然后按 **Enter** 以将该言语提交到列表中。\r\n",
        "3. 在“*turn the light on*”言语下，单击“light”一词，然后将其分配给 **device** 实体的 **light** 值。\r\n",
        "\r\n",
        "![如何将“light”一词分配给实体值。](./images/assign_entity.jpg)\r\n",
        "\r\n",
        "4. 使用短语“***turn the fan on***”，向 **switch_on** 意向添加第二条言语。然后，将“fan”一词分配给 **device** 实体的 **fan** 值。\r\n",
        "5. 在左侧窗格中，单击“**意向**”，然后单击“**创建**”，以添加另一个名为 **switch_off** 的意向。\r\n",
        "6. 在 **switch_off** 意向的“**言语**”页面中，添加言语“***turn the light off***”，将“light”一词分配给 **device** 实体的 **light** 值。\r\n",
        "7. 使用短语“***turn the fan off***”，向 **switch_off** 意向添加第二条言语。然后，将“fan”一词连接到 **device** 实体的 **fan** 值。\r\n",
        "\r\n",
        "### 训练并测试语言模型\r\n",
        "\r\n",
        "现在，你可以使用以实体、意向和言语形式提供的数据来训练应用的语言模型。\r\n",
        "\r\n",
        "1. 在应用的“语言理解”页顶部，单击“**训练**”以训练语言模型\r\n",
        "2. 训练模型后，单击“**测试**”，然后使用“测试”窗格查看以下短语的预测意向：\r\n",
        "    * *switch the light on*\r\n",
        "    * *turn off the fan*\r\n",
        "    * *turn the lamp off*\r\n",
        "    * *switch on the AC*\r\n",
        "3. 关闭“测试”窗格。\r\n",
        "    \r\n",
        "### 发布模型并配置终结点\r\n",
        "\r\n",
        "若要在客户端应用程序中使用经过训练的模型，必须将其发布为一种终结点（客户端应用程序可向其发送新言语）；从中可预测出意向和实体。\r\n",
        "\r\n",
        "1. 在应用的“语言理解”页顶部，单击“**发布**”。然后选择“**生产槽**”，并单击“**完成**”。\r\n",
        "\r\n",
        "2. 发布模型后，在应用的“语言理解”页顶部，单击“**管理**”。然后在“**设置**”选项卡上，记下应用的**应用 ID**。复制此 ID 并将其粘贴在下面的代码中，替换“**YOUR_LU_APP_ID**”。\r\n",
        "\r\n",
        "3. 在“**Azure 资源**”选项卡上，记下预测资源的**主键**和**终结点 URL**。复制它们并将其粘贴到下面的代码中，替换“**YOUR_LU_KEY**” 和“**YOUR_LU_ENDPOINT**”。\r\n",
        "\r\n",
        "4. 单击其“**运行单元格**”(&#9655;) 按钮（位于该单元格左侧），以运行下面的单元格，然后在出现提示时，输入文本“*turn the light on*”。文本由你的语言理解模型解读，同时会显示适当的图像。\r\n",
        "\r\n",
        "### **(!)重要事项**： \r\n",
        "在窗口顶部查找提示。你将需要键入“*turn the light on*”，然后按 **Enter**。 \r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from python_code import luis\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    # Set up API configuration\n",
        "    luis_app_id = 'YOUR_LU_APP_ID'\n",
        "    luis_key = 'YOUR_LU_KEY'\n",
        "    luis_endpoint = 'YOUR_LU_ENDPOINT'\n",
        "\n",
        "    # prompt for a command\n",
        "    command = input('Please enter a command: \\n')\n",
        "\n",
        "    # get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, command)\n",
        "\n",
        "    # display an appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696381331
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (!)签入 \r\n",
        "你是否已运行上面的单元格，然后在出现提示时输入了短语“*turn the light on*”？提示将出现在窗口顶部。  \r\n",
        "\r\n",
        "重新运行上面的单元格，并尝试以下短语：\r\n",
        "\r\n",
        "* *turn on the light*\r\n",
        "* *put the lamp off*\r\n",
        "* *switch the fan on*\r\n",
        "* *switch the light on*\r\n",
        "* *switch off the light*\r\n",
        "* *turn off the fan*\r\n",
        "* *switch the AC on*\r\n",
        "\r\n",
        "如果你运行上面的单元格，而其中显示了问号图像，则表示你使用的文本或间距可能与创建实体、意向或言语时所指示的略有不同。\r\n",
        "\r\n",
        "> **备注**：如果你对用于从语言理解应用检索意向和实体的代码感到好奇，请查看“**python_code**”文件夹中的 **luis.py** 文件。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 添加语音控制\r\n",
        "\r\n",
        "目前，我们已经了解到如何分析文本；但越来越多的 AI 系统使人们能够通过语音识别与软件服务进行交流。为支持这一点，**语音**认知服务提供了一种简单的方法来将口语转录成文本。\r\n",
        "\r\n",
        "### 创建认知服务资源\r\n",
        "\r\n",
        "请按照以下步骤在 Azure 订阅中创建**认知服务**资源（如果还没有该资源）：\r\n",
        "\r\n",
        "> **备注**：如果已有认知服务资源，则只需在 Azure 门户中打开其“**快速入门**”页，然后将其键和位置复制到下面的单元格中即可。否则，请按照以下步骤创建认知服务资源。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 ([https://portal.azure.com](https://portal.azure.com)) 并使用 Microsoft 帐户登录。\r\n",
        "2. 单击“**&#65291;创建资源**”按钮，搜索“*认知服务*”并以如下设置创建**认知服**务资源：\r\n",
        "    - **订阅**： *你的 Azure 订阅*。\r\n",
        "    - **资源组**： *选择或创建具有唯一名称的资源组*。\r\n",
        "    - **区域**： *选择任何可用区域*：\r\n",
        "    - **名称**： *输入一个唯一名称*。\r\n",
        "    - **定价层**：中的机器人 S0\r\n",
        "    - **选中此框即表示我确认该服务不会由美国警察局使用或用于美国警察局**：已选中。\r\n",
        "    - **我确认我已阅读并理解上述通知**：已选中。\r\n",
        "3. 等待部署完成。然后转到认知服务资源，并在“**快速入门**”页上，记下密钥和位置。你将需要这些信息来从客户端应用程序连接到认知服务资源。\r\n",
        "\r\n",
        "### 获取认知服务资源的密钥和位置\r\n",
        "\r\n",
        "要使用认知服务资源，需要向客户端应用程序提供其身份验证密钥和位置：\r\n",
        "\r\n",
        "1. 进入 Azure 门户，在认知服务资源的“**密钥和终结点**”页面上复制资源的“**Key1**”，并将其粘贴到以下代码中，替换“**YOUR_COG_KEY**”。\r\n",
        "2. 复制资源的**位置**并将其粘贴至以下代码中，替换“**YOUR_COG_LOCATION**”。\r\n",
        ">**备注**：停留在“**密钥和终结点**”页面上，并从其中复制“**位置**”（例如：_westus_）。请*不要*在“位置”字段的字词之间添加空格。 \r\n",
        "3. 在下面的单元格中运行代码。 "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696409914
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在，运行下面的单元格以转录音频文件中的语音，并将其用作语言理解应用的命令。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from python_code import luis\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "from playsound import playsound\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "try:   \n",
        "\n",
        "    # Get spoken command from audio file\n",
        "    file_name = 'light-on.wav'\n",
        "    audio_file = os.path.join('data', 'luis', file_name)\n",
        "\n",
        "    # Configure speech recognizer\n",
        "    speech_config = SpeechConfig(cog_key, cog_location)\n",
        "    audio_config = AudioConfig(filename=audio_file) # 使用文件而不是默认值（麦克风）\n",
        "    speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "    # Use a one-time, synchronous call to transcribe the speech\n",
        "    speech = speech_recognizer.recognize_once()\n",
        "\n",
        "    # Get the predicted intent and entity (code in python_code.home_auto.py)\n",
        "    action = luis.get_intent(luis_app_id, luis_key, luis_endpoint, speech.text)\n",
        "\n",
        "    # Get the appropriate image\n",
        "    img_name = action + '.jpg'\n",
        "\n",
        "    # Display image\n",
        "    img = Image.open(os.path.join(\"data\", \"luis\" ,img_name))\n",
        "    plt.axis('off')\n",
        "    plt. imshow(img)\n",
        "    playsound(audio_file)\n",
        "\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1599696420498
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "尝试修改上面的单元格以使用音频文件 **light-off.wav**。\r\n",
        "\r\n",
        "## 了解详细信息\r\n",
        "\r\n",
        "在[服务文档](https://docs.microsoft.com/azure/cognitive-services/luis/)中了解有关语言理解的详细信息"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}