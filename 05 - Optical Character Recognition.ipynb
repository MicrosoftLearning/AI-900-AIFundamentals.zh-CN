{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 光学字符识别\r\n",
        "\r\n",
        "![正在读报纸的机器人](./images/ocr.jpg)\r\n",
        "\r\n",
        "检测和解释图像中的文本是一个常见的计算机视觉难题。此类过程通常被称为“*光学字符识别*”(OCR)。\r\n",
        "\r\n",
        "## 使用计算机视觉服务读取图像中的文本\r\n",
        "\r\n",
        "**计算机视觉**认知服务可为 OCR 任务提供支持，包括：\r\n",
        "\r\n",
        "- 可用于读取多种语言的文本的 **OCR** API。此 API 可以同步使用，非常适合检测和读取图像中的少量文本。\r\n",
        "- 针对较大文档进行了优化的**读取** API。此 API 以异步方式使用，可用于读取印刷体文本和手写文本。\r\n",
        "\r\n",
        "可以通过创建**计算机视觉**资源或**认知服务**资源来使用此服务。\r\n",
        "\r\n",
        "如果还没有创建资源，请在 Azure 订阅中创建**认知服务**资源。\r\n",
        "\r\n",
        "> **备注**：如果已有认知服务资源，则只需在 Azure 门户中打开其“**快速入门**”页面，然后将其密钥和终结点复制到下面的单元格中即可。否则，请按照以下步骤创建认知服务资源。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 (https://portal.azure.com) 并使用 Microsoft 帐户登录。\r\n",
        "\r\n",
        "2. 单击“**&#65291;创建资源**”按钮，搜索“*认知服务*”并以如下设置创建**认知服务**资源：\r\n",
        "    - **订阅**： *你的 Azure 订阅*。\r\n",
        "    - **资源组**： *选择或创建具有唯一名称的资源组*。\r\n",
        "    - **区域**： *选择任何可用区域*：\r\n",
        "    - **名称**： *输入一个唯一名称*。\r\n",
        "    - **定价层**：中的机器人 S0\r\n",
        "    - **我确认我已阅读并理解上述通知**：已选中。\r\n",
        "3. 等待部署完成。然后转到认知服务资源，并单击“**概述**”页面上的链接以管理该服务的密钥。你将需要使用终结点和密钥从客户端应用程序连接到认知服务资源。\r\n",
        "\r\n",
        "### 获取认知服务资源的密钥和终结点\r\n",
        "\r\n",
        "要使用认知服务资源，客户端应用程序需要其终结点和身份验证密钥：\r\n",
        "\r\n",
        "1. 进入 Azure 门户，在认知服务资源的“**密钥和终结点**”页面上复制资源的“**Key1**”，并将其粘贴到以下代码中，替换“**YOUR_COG_KEY**”。\r\n",
        "2. 复制资源的**终结点**，并将其粘贴到以下代码中，替换“**YOUR_COG_ENDPOINT**”。\r\n",
        "3. 通过单击位于单元格左侧的“**运行单元格**”(&#9655;) 按钮运行下方单元格中的代码。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694246277
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在你已设置好密钥和终结点，可以使用计算机视觉服务资源来提取图像中的文本。\r\n",
        "\r\n",
        "我们先使用 **OCR** API，该 API 可用于同步分析图像并读取其中包含的所有文本。在本例中，我们使用虚构的 Northwind Traders 零售公司的广告图，该图中包含一些文本。运行下面的单元格来读取这些文本。 "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "## Use the Computer Vision service to find text in the image\r\n",
        "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694257280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "图像中的文本被整理为由区域、行和字词构成的层次结构，代码会读取这些内容以检索结果。\r\n",
        "\r\n",
        "在结果中，查看在图像上读取到的文本。 \r\n",
        "\r\n",
        "## 显示边界框\r\n",
        "\r\n",
        "结果中还包括在图像中查找到的文本行和单独字词的*边界框*坐标。运行下面的单元格，查看上面检索的广告图中文本行的边界框。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Show the position of the line of text\n",
        "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
        "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Show the image with the text locations highlighted\r\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694266106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在结果中，每行文本的边界框都显示为图像上的矩形。\r\n",
        "\r\n",
        "## 使用读取 API\r\n",
        "\r\n",
        "前面使用的 OCR API 非常适合处理带有少量文本的图像。在需要读取较大篇幅的文本（例如扫描出的文档）时，则可以使用**读取** API。此过程需要完成多个步骤：\r\n",
        "\r\n",
        "1. 向计算机视觉服务提交一个要以异步方式读取和分析的图像。\r\n",
        "2. 等待分析操作完成。\r\n",
        "3. 检索分析结果。\r\n",
        "\r\n",
        "运行以下单元格，使用此过程读取发送给 Northwind Traders 商店经理的扫描信件中的文本。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694312346
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看结果。结果中完整转录出了信件内容，大部分内容都是印刷体文本，还有一个手写签名。信件的原始图像显示在 OCR 结果下方（可能需要滚动鼠标才能看到）。\r\n",
        "\r\n",
        "## 读取手写文本\r\n",
        "\r\n",
        "在前面的示例中，分析图像的请求指定了已针对读取*印刷*体文本进行了优化的文本识别模式。值得注意的是，尽管只是针对读取印刷体文本进行了优化，仍然读取到了手写签名。\r\n",
        "\r\n",
        "这种读取手写文本的能力非常有用。例如，假设你写了一张包含购物清单的便条，并想使用手机上的应用来读取并转录其中包含的文本。\r\n",
        "\r\n",
        "运行下面的单元格，查看手写购物清单的读取操作示例。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'note.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image and display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694340593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 更多信息\r\n",
        "\r\n",
        "要详细了解如何使用计算机视觉服务完成 OCR，请参阅[计算机视觉文档](https://docs.microsoft.com/zh-cn/azure/cognitive-services/computer-vision/concept-recognizing-text)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}