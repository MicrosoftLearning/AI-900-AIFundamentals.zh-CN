{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 语音\r\n",
        "\r\n",
        "我们越来越希望能通过对人工智能 (AI) 系统说话的方式来与其进行交流，而且通常希望它们也能通过“说话”来进行回应。\r\n",
        "\r\n",
        "![正在说话的机器人](./images/speech.jpg)\r\n",
        "\r\n",
        "*语音识别*（对口头语言进行解释的 AI 系统）和*语音合成*（生成语音响应的 AI 系统）是支持语音的 AI 解决方案的关键组件。\r\n",
        "\r\n",
        "## 创建认知服务资源\r\n",
        "\r\n",
        "要生成能解释语音并做出语音回应的软件，可以使用**语音**认知服务，该服务提供了一种在口头语言和文本之间相互转录的简单方法。\r\n",
        "\r\n",
        "请按照以下步骤在 Azure 订阅中创建**认知服务**资源（如果还没有该资源）：\r\n",
        "\r\n",
        "> **备注**：如果已有认知服务资源，则只需在 Azure 门户中打开其“**快速入门**”页面，然后将其密钥和终结点复制到下面的单元格中即可。否则，请按照以下步骤创建认知服务资源。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 (https://portal.azure.com) 并使用 Microsoft 帐户登录。\r\n",
        "2. 单击“**&#65291;创建资源**”按钮，搜索“*认知服务*”并以如下设置创建**认知服务**资源：\r\n",
        "    - **订阅**： *你的 Azure 订阅*。\r\n",
        "    - **资源组**： *选择或创建具有唯一名称的资源组*。\r\n",
        "    - **区域**： *选择任何可用区域*：\r\n",
        "    - **名称**： *输入一个唯一名称*。\r\n",
        "    - **定价层**：中的机器人 S0\r\n",
        "    - **我确认我已阅读并理解上述通知**：已选中。\r\n",
        "3. 等待部署完成。然后转到认知服务资源，并单击“**概述**”页面上的链接以管理该服务的密钥。你将需要使用密钥和位置从客户端应用程序连接到认知服务资源。\r\n",
        "\r\n",
        "### 获取认知服务资源的密钥和位置\r\n",
        "\r\n",
        "要使用认知服务资源，需要向客户端应用程序提供其身份验证密钥和位置：\r\n",
        "\r\n",
        "1. 进入 Azure 门户，在认知服务资源的“**密钥和终结点**”页面上复制资源的“**Key1**”，并将其粘贴到以下代码中，替换“**YOUR_COG_KEY**”。\r\n",
        "2. 复制资源的**位置**并将其粘贴到以下代码中，替换“**YOUR_COG_LOCATION**”。\r\n",
        ">**备注**：停留在“**密钥和终结点**”页面上，并从其中复制“**位置**”（例如：_westus_）。请*不要*在“位置”字段的字词之间添加空格。 \r\n",
        "3. 通过单击位于单元格左侧的“**运行单元格**”(&#9655;) 按钮运行下方代码。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      },
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 语音识别\r\n",
        "\r\n",
        "假设你要构建一个家庭自动化系统，并使其能够接受语音指令，例如“turn the light on”或“turn the light off”。你的应用程序要能接收基于音频的输入（即语音指令），并将其转录为能被解析和分析的文本，从而对其进行解释。\r\n",
        "\r\n",
        "现已准备好转录部分语音。可以通过**麦克风**或**音频**文件进行输入。 \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 使用音频文件的语音识别\r\n",
        "\r\n",
        "运行下面的单元格，查看使用**音频文件**进行输入的语音识别服务的运行情况。 \r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# Get spoken command from audio file\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# Configure speech recognizer\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# Use a one-time, synchronous call to transcribe the speech\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# Play the original audio file\r\n",
        "playsound(audio_file)\n",
        "\n",
        "# Show transcribed text from audio file\r\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 语音合成\r\n",
        "\r\n",
        "现在你已了解如何使用语音服务将语音转录成文本，那反过来该如何操作呢？如何将文本转换成语音？\r\n",
        "\r\n",
        "让我们假设你的家庭自动化系统已经解释出了开灯命令。适当的回应可能是口头表明接受命令，当然也要实际执行命令的任务！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# Get text to be spoken\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# Configure speech synthesis\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_config.speech_synthesis_voice_name = 'en-US-ChristopherNeural'\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# Transcribe text into speech\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# Display an appropriate image \r\n",
        "file_name = response_text.lower() + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请尝试将变量 **response_text** 更改为“*Turning the light off.*”（包括句尾的标点），然后再次运行单元格，听听结果。\r\n",
        "\r\n",
        "## 了解详细信息\r\n",
        "\r\n",
        "此笔记本中介绍的是一个非常简单的语音认知服务使用示例。可以在语音服务文档中详细了解[语音转文本](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text)和[文本转语音](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech)。"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}